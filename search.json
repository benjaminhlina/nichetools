[{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"CC0 1.0 Universal","title":"CC0 1.0 Universal","text":"CREATIVE COMMONS CORPORATION LAW FIRM PROVIDE LEGAL SERVICES. DISTRIBUTION DOCUMENT CREATE ATTORNEY-CLIENT RELATIONSHIP. CREATIVE COMMONS PROVIDES INFORMATION “-” BASIS. CREATIVE COMMONS MAKES WARRANTIES REGARDING USE DOCUMENT INFORMATION WORKS PROVIDED HEREUNDER, DISCLAIMS LIABILITY DAMAGES RESULTING USE DOCUMENT INFORMATION WORKS PROVIDED HEREUNDER.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/LICENSE.html","id":"statement-of-purpose","dir":"","previous_headings":"","what":"Statement of Purpose","title":"CC0 1.0 Universal","text":"laws jurisdictions throughout world automatically confer exclusive Copyright Related Rights (defined ) upon creator subsequent owner(s) (, “owner”) original work authorship /database (, “Work”). Certain owners wish permanently relinquish rights Work purpose contributing commons creative, cultural scientific works (“Commons”) public can reliably without fear later claims infringement build upon, modify, incorporate works, reuse redistribute freely possible form whatsoever purposes, including without limitation commercial purposes. owners may contribute Commons promote ideal free culture production creative, cultural scientific works, gain reputation greater distribution Work part use efforts others. /purposes motivations, without expectation additional consideration compensation, person associating CC0 Work (“Affirmer”), extent owner Copyright Related Rights Work, voluntarily elects apply CC0 Work publicly distribute Work terms, knowledge Copyright Related Rights Work meaning intended legal effect CC0 rights. Copyright Related Rights. Work made available CC0 may protected copyright related neighboring rights (“Copyright Related Rights”). Copyright Related Rights include, limited , following: right reproduce, adapt, distribute, perform, display, communicate, translate Work; moral rights retained original author(s) /performer(s); publicity privacy rights pertaining person’s image likeness depicted Work; rights protecting unfair competition regards Work, subject limitations paragraph 4(), ; rights protecting extraction, dissemination, use reuse data Work; database rights (arising Directive 96/9/EC European Parliament Council 11 March 1996 legal protection databases, national implementation thereof, including amended successor version directive); similar, equivalent corresponding rights throughout world based applicable law treaty, national implementations thereof. Waiver. greatest extent permitted , contravention , applicable law, Affirmer hereby overtly, fully, permanently, irrevocably unconditionally waives, abandons, surrenders Affirmer’s Copyright Related Rights associated claims causes action, whether now known unknown (including existing well future claims causes action), Work () territories worldwide, (ii) maximum duration provided applicable law treaty (including future time extensions), (iii) current future medium number copies, (iv) purpose whatsoever, including without limitation commercial, advertising promotional purposes (“Waiver”). Affirmer makes Waiver benefit member public large detriment Affirmer’s heirs successors, fully intending Waiver shall subject revocation, rescission, cancellation, termination, legal equitable action disrupt quiet enjoyment Work public contemplated Affirmer’s express Statement Purpose. Public License Fallback. part Waiver reason judged legally invalid ineffective applicable law, Waiver shall preserved maximum extent permitted taking account Affirmer’s express Statement Purpose. addition, extent Waiver judged Affirmer hereby grants affected person royalty-free, non transferable, non sublicensable, non exclusive, irrevocable unconditional license exercise Affirmer’s Copyright Related Rights Work () territories worldwide, (ii) maximum duration provided applicable law treaty (including future time extensions), (iii) current future medium number copies, (iv) purpose whatsoever, including without limitation commercial, advertising promotional purposes (“License”). License shall deemed effective date CC0 applied Affirmer Work. part License reason judged legally invalid ineffective applicable law, partial invalidity ineffectiveness shall invalidate remainder License, case Affirmer hereby affirms () exercise remaining Copyright Related Rights Work (ii) assert associated claims causes action respect Work, either case contrary Affirmer’s express Statement Purpose. Limitations Disclaimers. trademark patent rights held Affirmer waived, abandoned, surrendered, licensed otherwise affected document. Affirmer offers Work -makes representations warranties kind concerning Work, express, implied, statutory otherwise, including without limitation warranties title, merchantability, fitness particular purpose, non infringement, absence latent defects, accuracy, present absence errors, whether discoverable, greatest extent permissible applicable law. Affirmer disclaims responsibility clearing rights persons may apply Work use thereof, including without limitation person’s Copyright Related Rights Work. , Affirmer disclaims responsibility obtaining necessary consents, permissions rights required use Work. Affirmer understands acknowledges Creative Commons party document duty obligation respect CC0 use Work.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"our-objectives","dir":"Articles","previous_headings":"","what":"Our Objectives","title":"Using {nichetools} with SIBER","text":"purpose vignette use {SIBER} {nichetools} extract visualize estimates trophic niche size similarities Layman community metrics multiple freshwater fish using {ggplot2}. vignette can used additional purposes including estimating niche size similarities among different groups aquatic /terrestrial species. Furthermore, niche size similarities different behaviours exhibited within population can made using behavioural data generated acoustic telemetry (e.g., differences habitat occupancy).","code":""},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"bring-in-trophic-data","dir":"Articles","previous_headings":"","what":"Bring in trophic data","title":"Using {nichetools} with SIBER","text":"First load necessary packages preform analysis visualization. use {SIBER} {nichetools} preform analysis. use {bayestestR} calculate extract medians Equal-Tailed Interval (ETI) posterior distributions want plot. use {dplyr}, {tidyr}, {purrr} manipulate data iterate processes. Lastly, use {ggplot2}, {ggtext}, {ggdist} plot add labels. add many dplyr tidyr functions processes can replaced using {data.table} great working large data sets. first load packages just mentioned purpose vignette using demo.siber.data.2 data frame available within {SIBER}. first look structure data frame using dplyr function glimpse(). purposes need replace data frame either loading csv, rds, qs file. can multiple ways, prefer using readr::read_csv() csv base R’s read.csv() works perfectly fine. Note, {SIBER} functions take tibbles data.tables convert either data.frame class prior running functions {SIBER}. notice community group column character strings actual names communities groups. advise changing factors, thus allow know order column prior converting numeric charcter. reason important, functions {SIBER} use loops based indexing SiberObject. order match can issues names communities groups working . Let us change factor, preserve column create id column numerical order become community group names provided createSiberObject(). done , going create two data frames names communities groups associated id values. use data frames later join actual names, allowing us know estimates belong communities groups. unlikely communities groups named 1, 2, 3 ect. instead actual names. plot biplot confirm correct structure.  Next grab isotopes need community group ids already renamed community group. important creatSiberObject() 1) take following order following names iso1, iso2, group, community 2) transform tibble data.frame {SIBER} work data.frame. case using tibbles also working data.table need thing.","code":"{   library(bayestestR)   library(dplyr)   library(ggplot2)   library(ggdist)   library(ggtext)   library(nichetools)   library(purrr)   library(SIBER)   library(tidyr)   library(viridis) } glimpse(demo.siber.data.2) #> Rows: 150 #> Columns: 4 #> $ iso1      <dbl> -11.048902, -8.809360, -9.256212, -8.380952, -10.401561, -7.… #> $ iso2      <dbl> 1.02044315, 1.97597511, 3.28707260, -1.95750266, -3.11949113… #> $ group     <chr> \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"cit… #> $ community <chr> \"dublin\", \"dublin\", \"dublin\", \"dublin\", \"dublin\", \"dublin\", … demo.siber.data.2 <- demo.siber.data.2 %>%   mutate(     group = factor(group),      community = factor(community),      group_id = as.numeric(group) %>%        as.character(),     community_id = as.numeric(community) %>%       as.character()   ) %>%    rename(     group_name = group,     community_name = community,     group = group_id,     community = community_id   )  glimpse(demo.siber.data.2) #> Rows: 150 #> Columns: 6 #> $ iso1           <dbl> -11.048902, -8.809360, -9.256212, -8.380952, -10.401561… #> $ iso2           <dbl> 1.02044315, 1.97597511, 3.28707260, -1.95750266, -3.119… #> $ group_name     <fct> city, city, city, city, city, city, city, city, city, c… #> $ community_name <fct> dublin, dublin, dublin, dublin, dublin, dublin, dublin,… #> $ group          <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", … #> $ community      <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", … # ---- create name with group and community data frame ---- cg_names <- demo.siber.data.2 %>%   distinct(group,            community,             group_name,             community_name) %>%      arrange(community, group)  # ---- create community names data frame ----  c_names <- demo.siber.data.2 %>%    distinct(community,             community_name) %>%   arrange(community) ggplot(data = demo.siber.data.2, aes(x = iso1, y = iso2,                                      colour = group_name)) +   geom_point() +   facet_wrap(~ community_name) +    scale_colour_viridis_d(option = \"A\", begin = 0.25, end = 0.85,                          name = \"Groups\", alpha = 0.75) +    theme_bw(     base_size = 15   ) +    theme(     strip.background = element_blank(),     panel.grid = element_blank(),      axis.title = element_markdown(),     legend.position = \"inside\",     legend.position.inside = c(0.65, 0.75)   ) +    labs(     x = paste0(\"\\U03B4\",\"<sup>\", 13, \"<\/sup>\", \"C\", \" (‰)\"),     y = paste0(\"\\U03B4\",\"<sup>\", 15, \"<\/sup>\", \"N\", \" (‰)\")   ) demo_siber_data <- demo.siber.data.2 %>%    dplyr::select(iso1, iso2, group, community) %>%   arrange(community, group) %>%    as.data.frame()"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"convert-to-siber-object","dir":"Articles","previous_headings":"","what":"Convert to {SIBER} object","title":"Using {nichetools} with SIBER","text":"First convert isotope data {SIBER} object. Now {SIBER} object can start analysis using frequentist (e.g., maximum-likelihood) Bayesian framework. data metrics generated analysis {SIBER} can extracted using functions nichetools.","code":"siber_example <- createSiberObject(demo_siber_data)"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"bayesian-ellipse-analysis","dir":"Articles","previous_headings":"","what":"Bayesian Ellipse Analysis","title":"Using {nichetools} with SIBER","text":"first need set parameters run model Next need define priors parameter model. includes fitting ellipses using Inverse Wishart prior covariance matrix (Σ\\Sigma), vague normal prior means (μ\\mu). now run model using function siberMVN().","code":"# options for running jags parms <- list() parms$n.iter <- 2 * 10^4   # number of iterations to run the model for parms$n.burnin <- 1 * 10^3 # discard the first set of values parms$n.thin <- 10     # thin the posterior by this many parms$n.chains <- 2        # run this many chains # fit the ellipses which uses an Inverse Wishart prior on the  # covariance matrix Sigma, and a vague normal prior on the  # means. priors <- list() priors$R <- 1 * diag(2) priors$k <- 2 priors$tau.mu <- 1.0E-3 ellipses_posterior <- siberMVN(siber_example, parms, priors)"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"extract-posterior-distributions-for-μ-and-σ","dir":"Articles","previous_headings":"","what":"Extract posterior distributions for μ and Σ","title":"Using {nichetools} with SIBER","text":"first extract posterior distribution μ\\mu using extract_mu() nichetools. need set argument pkg \"SIBER\" argument data_format \"wide\". argument takes \"long\" \"wide\" dictates whether data object returned wide long format. also use function seperate_wider_delim() tidyr separate community groups names joined .. use left_join() cg_names data frame created add correct community group names. can confirm posterior estimates μ\\mu correct plotting {ggplot2}.  Notice density points center raw data corresponding colours. density points posterior estimates model μ\\mu indication model iterating groups communities correctly. also going extract μ\\mu long format creating ellipse, function create ellipse needs data frame μ\\mu long format. Next going extract posterior estimates Σ\\Sigma using extract_sigma(). Lastly, going feed μ\\mu Σ\\Sigma estimate niche_ellipse() estimate ellipse. things know function include following: 1) randomly sample 10 ellipse total posterior distribution μ\\mu Σ\\Sigma, seems quite standard, however, can adjust number samples changing argument n. 2) make function consistently randomly sample set need set set_seed numerical value. set randomly sample different set 10 ellipses every time. 3) like function randomly sample set argument random FALSE. 4) default tell long takes generate ellipse progress bars step. want turn set message FALSE. 5) wanting change confidence level ellipse can using argument p_ell. value bound 0 1. Now ellipses created can plot .","code":"df_mu <- extract_mu(ellipses_posterior, pkg = \"SIBER\",                      data_format = \"wide\",                      community_df = cg_names) ggplot() +   geom_point(data = df_mu, aes(x = d13c, y = d15n,                                colour = group_name)) +   geom_point(data = demo.siber.data.2, aes(x = iso1, y = iso2,                                            colour = group_name)) +   facet_wrap( ~ community_name) +    scale_colour_viridis_d(option = \"A\", begin = 0.25, end = 0.85,                          name = \"Groups\", alpha = 0.75) +    theme_bw(     base_size = 15   ) +    theme(     strip.background = element_blank(),     panel.grid = element_blank(),      axis.title = element_markdown(),     legend.position = \"inside\",     legend.position.inside = c(0.65, 0.75)   ) +    labs(     x = paste0(\"\\U03B4\",\"<sup>\", 13, \"<\/sup>\", \"C\", \" (‰)\"),     y = paste0(\"\\U03B4\",\"<sup>\", 15, \"<\/sup>\", \"N\", \" (‰)\")   ) df_mu_long <- extract_mu(ellipses_posterior, pkg = \"SIBER\",                           community_df = cg_names) df_sigma <- extract_sigma(ellipses_posterior, pkg = \"SIBER\") df_el <- niche_ellipse(dat_mu = df_mu_long,                        dat_sigma = df_sigma,                         set_seed = 4, n = 20) %>%   separate_wider_delim(sample_name, cols_remove = FALSE,                        delim = \".\", names = c(\"community\",                                               \"group\")) %>%   left_join(cg_names) ggplot(data = df_el,         aes(x = d13c, y = d15n,             group = interaction(sample_number,                                 sample_name),             colour = group_name)) +    geom_polygon(linewidth = 0.5, fill = NA) +    facet_wrap( ~ community_name) +    scale_colour_viridis_d(option = \"A\", begin = 0.25, end = 0.85,                          name = \"Groups\", alpha = 0.75) +    theme_bw(     base_size = 15   ) +    theme(     strip.background = element_blank(),     panel.grid = element_blank(),      legend.position = \"inside\",     axis.title = element_markdown(),     legend.background = element_blank(),      legend.position.inside = c(0.65, 0.75)   ) +    labs(     x = paste0(\"\\U03B4\",\"<sup>\", 13, \"<\/sup>\", \"C\", \" (‰)\"),     y = paste0(\"\\U03B4\",\"<sup>\", 15, \"<\/sup>\", \"N\", \" (‰)\")   )"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"extract-niche-size","dir":"Articles","previous_headings":"","what":"Extract Niche Size","title":"Using {nichetools} with SIBER","text":"can use siberEllipses() {SIBER} estimate niche size posterior sample community group. Next using extract_niche_size() nichetools can extract niche size also add correct names communities groups working . also extract parametric estimate niche size using groupMetricsML() {SIBER}. can convert output function using extract_group_metrics(). object returned maximum-likelihood estimates standard ellipse area (SEA), central standard ellipse area (SEAc), total area (TA). plotting niche size use SEAc. Lastly, can visualize extracted niche sizes using {ggplot2}.","code":"sea_b <- siberEllipses(corrected.posteriors = ellipses_posterior) seb_convert <- extract_niche_size(data = sea_b,                                   pkg = \"SIBER\",                                   community_df = cg_names) group_ml <- groupMetricsML(siber_example) group_convert <- extract_group_metrics(data = group_ml,                                        community_df = cg_names) sea_c <- group_convert %>%    filter(metric == \"SEAc\") ggplot() +   geom_violin(data = seb_convert, aes(x = community_name,                                       y = sea,                                       fill = group_name)) +    scale_fill_viridis_d(option = \"A\", begin = 0.25, end = 0.85,                        name = \"Groups\", alpha = 0.75) +    geom_point(data = sea_c, aes(x = community_name,                                 y = est,                                 group = group_name,   ),    size = 2.5,   fill = \"white\",   shape = 21,   position = position_dodge(width = 0.9)) +   theme_bw(     base_size = 15   ) +    theme(     strip.background = element_blank(),     panel.grid = element_blank(),      legend.position = \"inside\",     legend.background = element_blank(),      legend.position.inside = c(0.85, 0.8)   ) +    labs(     x = \"Communities\",      y = expression(paste(\"Niche Size p(\", \"‰\"^2, \"| x)\"))   )"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"niche-similarties","dir":"Articles","previous_headings":"","what":"Niche Similarties","title":"Using {nichetools} with SIBER","text":"Now extracted Bayesian estimates niche size likely wanting know much niches common similar. can use maximum-likelihood Bayesian frameworks estimate percentage similarity within communities groups /among communities groups consistent. can use functions {SIBER} create maximum-likelihood Bayesian estimates niche similarity followed functions nichetools extract similarities. First need create comparisons wanting evaluate. can use function create_comparisons() generate list two-column data frames comparison. can change argument comparison \"among\" compare communities group, versus \"within\" compares groups within community. Next can feed listed data frames either maxLikOverlap() bayesianOverlap() using map() purrr. exercise changed .progress argument map() working large data sets often turn argument TRUE provide progress update. Next can extract estimates using extract_similarities() type argument set \"ml\". Now repeat process bayesianOverlap(), first supplying function list data frames, next map() iterate list. Next can extract estimates using extract_similarities() type argument set \"bay\". Now extracted maximum-likelihood Bayesian estimates can visualize . Prior creating point interval plot, need create colour palette used identify community. Now can use point interval plots visually represent posterior distributions.","code":"cg_names_within_com <- cg_names %>%   create_comparisons(comparison = \"within\") ml_within_overlap <- cg_names_within_com %>%   map(~ maxLikOverlap(.x$cg_1, .x$cg_2, siber_example,                       p.interval = 0.95, n = 100)) ml_95_within_com <- extract_similarities(ml_within_overlap,                                           type = \"ml\",                                           community_df = cg_names) bayes95_overlap <- cg_names_within_com %>%   map(~ bayesianOverlap(.x$cg_1, .x$cg_2, ellipses_posterior,                         draws = 100, p.interval = 0.95,                         n = 100)   ) bays_95_overlap <- extract_similarities(bayes95_overlap,                                          type = \"bay\",                                         community_df = cg_names) viridis_colors_s <- viridis(4, begin = 0.25, end = 0.85,                           option = \"A\",                           alpha = 0.75 ) ggplot() +    stat_pointinterval(data = bays_95_overlap,               aes(x = group_1,                    y = prop_overlap,                    point_fill = group_2),      interval_colour = \"grey60\",     point_size = 3,     shape = 21,     position = position_dodge(0.4)) +       geom_point(data = ml_95_within_com, aes(x = group_1,                                     y = prop_overlap,                                    group = group_2),               shape = 21,              fill = \"white\",              size = 2,              alpha = 0.5,               position = position_dodge(0.4)) +    scale_fill_manual(name = \"Group\",                      aesthetics = \"point_fill\",                     values = viridis_colors_s) +    theme_bw(     base_size = 15   ) +    theme(     panel.grid = element_blank(),     strip.background = element_blank(),     legend.position = \"inside\",     legend.position.inside = c(0.15, 0.80),   ) +   labs(     x = \"Group\",     y = expression(paste(\"p(\", \"‰\", \"|X)\"))   )"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-SIBER.html","id":"bayesian-estimates-of-laymans-community-metrics","dir":"Articles","previous_headings":"","what":"Bayesian Estimates of Layman’s Community Metrics","title":"Using {nichetools} with SIBER","text":"First highly recommend reading Layman et al. 2007 understand six community metrics estimating using Bayesian framework section. create maximum-likelihood estimate Layman’s community metrics first need use communityMetricsML() {SIBER}. can extract estimates using extract_layman() type argument set \"ml\". default argument \"bay\". create Bayesian estimates Layman’s community metrics first need use extractPosteriorMeans() {SIBER} extract posterior estimates means community group. Next need use bayesianLayman() {SIBER} use extracted posterior means create Bayesian estimates community metric. created Bayesian estimates community metric can use extract_layman() extract estimates. function also create variable labels first assign new name community metric secondly reorder names based metrics often viewed. Prior creating point interval plot, need create colour palette used identify community. Lastly, can visualize distributions posterior estimates using stat_pointinterval() {ggdist}.  Congratulations, successfully used functions {SIBER} extract visually represent trophic communities niche size similarities. something doesn’t work/confusing please reach .","code":"community_ml <- communityMetricsML(siber_example) layman_ml <- extract_layman(community_ml,                              type = \"ml\",                              community_df = c_names) mu_post <- extractPosteriorMeans(siber_example, ellipses_posterior) layman_b <- bayesianLayman(mu.post = mu_post) layman_be <- extract_layman(layman_b, community_df = c_names) viridis_colors <- viridis(2, begin = 0.25, end = 0.85,                           option = \"G\",                           alpha = 0.75 ) ggplot() +    stat_pointinterval(     data = layman_be, aes(x = labels,                            y = post_est,                            point_fill = community_name),     point_size = 2.5,     interval_colour = \"grey60\",     position = position_dodge(0.4),     shape = 21   ) +    geom_point(data = layman_ml, aes(x = labels,                                     y = estimate,                                    group = community_name),               shape = 21,              fill = \"white\",              alpha = 0.5,               position = position_dodge(0.4)) +    scale_fill_manual(name = \"Community\",                      aesthetics = \"point_fill\",                     values = viridis_colors) +    theme_bw(     base_size = 15   ) +    theme(     panel.grid = element_blank(),     axis.text = element_markdown(),     legend.position = \"inside\",     legend.position.inside = c(0.88, 0.85),   ) +   labs(     x = \"Community Metrics\",     y = expression(paste(\"p(\", \"‰\", \"|X)\"))   )"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"our-objectives","dir":"Articles","previous_headings":"","what":"Our Objectives","title":"Using {nichetools} with nicheROVER","text":"purpose vignette use {nicheROVER} {nichetools} extract visualize estimates trophic niche size similarities multiple freshwater fish using {ggplot2}. vignette can used additional purposes including estimating niche size similarities among different groups aquatic /terrestrial species. Furthermore, niche size similarities different behaviours exhibited within population can made using behavioural data generated acoustic telemetry (e.g., differences habitat occupancy).","code":""},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"bring-in-trophic-niche-data","dir":"Articles","previous_headings":"","what":"Bring in trophic niche data","title":"Using {nichetools} with nicheROVER","text":"First load necessary packages preform analysis visualization. use {nicheROVER} {nichetools} preform analysis. use {dplyr}, {tidyr}, {purrr} manipulate data iterate processes. Lastly, use {ggplot2}, {ggtext}, {patchwork} plot, add labels, arrange plots. add many dplyr tidyr functions processes can replaced using {data.table} great working large data sets. purpose vignette using fish data frame available within nicheROVER. remove δ\\delta34S simplicity vignette. two isotopes metrics used compare niche sizes similarities, please use functions pairing. Right now functions (.e., niche_ellipse()) nichetools doesn’t ability work two isotopes. become feature point now. Please patient use functions pairing . first use function janitor::clean_names() clean column names. purposes need replace fish data frame either loading csv, rds, qs, data. can multiple ways, prefer using readr::read_csv() base R’s read.csv() works perfectly fine. isotopic values run NA, need removed nicheROVER’s functions accommodate values NA.","code":"{   library(dplyr)   library(ggplot2)   library(ggtext)   library(ggh4x)   library(nicheROVER)    library(nichetools)   library(patchwork)   library(purrr)   library(stringr)   library(tidyr) } df <- fish %>%    janitor::clean_names()"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"estimate-posterior-distribution-with-normal-inverse-wishart-niw-priors-","dir":"Articles","previous_headings":"","what":"Estimate posterior distribution with Normal-Inverse-Wishart (NIW) priors.","title":"Using {nichetools} with nicheROVER","text":"take 1,000 posterior samples group. can change suggest nothing less 1,000. split data frame list species data frame object within list, iterate list, using map() {purrr}, estimate posterior distribution using Normal-Inverse-Wishart (NIW) priors.","code":"nsample <- 1000 fish_par <- df %>%    split(.$species) %>%    map(~ select(., d13c, d15n)) %>%    map(~ niw.post(nsample = nsample, X = .))"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"extract-μ-values","dir":"Articles","previous_headings":"","what":"Extract μ values","title":"Using {nichetools} with nicheROVER","text":"use extract_mu()extract posteriors μ\\mu estimates. default output extract_mu() long format works plotting {ggplot2} functions {nichetools}. want wide format can specify argument format \"wide\", however, unlikely need data wide format. default output lacking info plotting. need add column element abbreviation neutron number used axis labeling.","code":"df_mu <- extract_mu(fish_par) df_mu <- df_mu %>%   mutate(     element = case_when(       isotope == \"d15n\" ~ \"N\",       isotope == \"d13c\" ~ \"C\",     ),      neutron = case_when(       isotope == \"d15n\" ~ 15,       isotope == \"d13c\" ~ 13,     )    )"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"extract-σ-values","dir":"Articles","previous_headings":"","what":"Extract Σ values","title":"Using {nichetools} with nicheROVER","text":"use extract_sigma() extract posterior estimates Σ\\Sigma. default output extract_sigma() wide format doesn’t work plotting {ggplot2} work functions {nichetools}. want long plotting can specify argument format \"long\". plotting need extracted Σ\\Sigma values long format. also need remove Σ\\Sigma values isotope columns isotope.","code":"df_sigma <- extract_sigma(fish_par) df_sigma_cn <- extract_sigma(fish_par,                               data_format = \"long\") %>%   filter(id != isotope)"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"plot-posterior-distrubtion-of-μ-and-σ","dir":"Articles","previous_headings":"","what":"Plot posterior distrubtion of μ and Σ","title":"Using {nichetools} with nicheROVER","text":"plotting within vignette, split() data frame isotope, creating list use imap() iterate list create plots. use geom_density() represent densities μ\\mu Σ\\Sigma. Plot objects stored list. First plot μ\\mu isotope. use {patchwork} configure plots multi-panel figures. package phenomenal uses math operators configure manipulate plots create multi-panel figures. labeling also going use element_markdown() {ggtext} work labels needed correctly display isotopic signature. working data please replace.  labeling purposes need add columns element abbreviation neutron number. using case_when() vectorized else statements. Next plot posteriors Σ\\Sigma.","code":"posterior_plots <- df_mu %>%   split(.$isotope) %>%   imap(     ~ ggplot(data = ., aes(x = mu_est)) +       geom_density(aes(fill = sample_name), alpha = 0.5) +       scale_fill_viridis_d(begin = 0.25, end = 0.75,                            option = \"D\", name = \"Species\") +       theme_bw() +       theme(panel.grid = element_blank(),             axis.title.x =  element_markdown(),             axis.title.y =  element_markdown(),             legend.position = \"none\",             legend.background = element_blank()       ) +       labs(         x = paste(\"\\u00b5<sub>\\U03B4<\/sub>\", \"<sub><sup>\",                   unique(.$neutron), \"<\/sup><\/sub>\",                   \"<sub>\",unique(.$element), \"<\/sub>\", sep = \"\"),         y = paste0(\"p(\\u00b5 <sub>\\U03B4<\/sub>\",\"<sub><sup>\",                    unique(.$neutron), \"<\/sub><\/sup>\",                    \"<sub>\",unique(.$element),\"<\/sub>\",                    \" | X)\"), sep = \"\")   )  posterior_plots$d15n +   theme(legend.position = c(0.18, 0.82)) +    posterior_plots$d13c df_sigma_cn <- df_sigma_cn %>%   mutate(     element_id = case_when(       id == \"d15n\" ~ \"N\",       id == \"d13c\" ~ \"C\",     ),     neutron_id = case_when(       id == \"d15n\" ~ 15,       id == \"d13c\" ~ 13,     ),     element_iso = case_when(       isotope == \"d15n\" ~ \"N\",       isotope == \"d13c\" ~ \"C\",     ),     neutron_iso = case_when(       isotope == \"d15n\" ~ 15,       isotope == \"d13c\" ~ 13,     )   ) sigma_plots <- df_sigma_cn %>%   group_split(id, isotope) %>%   imap(     ~ ggplot(data = ., aes(x = post_sample)) +       geom_density(aes(fill = sample_name), alpha = 0.5) +       scale_fill_viridis_d(begin = 0.25, end = 0.75,                            option = \"D\", name = \"Species\") +       theme_bw() +       theme(panel.grid = element_blank(),             axis.title.x =  element_markdown(),             axis.title.y =  element_markdown(),             legend.position = \"none\"       ) +       labs(         x = paste(\"\\U03A3\",\"<sub>\\U03B4<\/sub>\",                   \"<sub><sup>\", unique(.$neutron_id), \"<\/sub><\/sup>\",                   \"<sub>\",unique(.$element_id),\"<\/sub>\",\" \",                   \"<sub>\\U03B4<\/sub>\",                   \"<sub><sup>\", unique(.$neutron_iso), \"<\/sub><\/sup>\",                   \"<sub>\",unique(.$element_iso),\"<\/sub>\", sep = \"\"),         y = paste(\"p(\", \"\\U03A3\",\"<sub>\\U03B4<\/sub>\",                   \"<sub><sup>\", unique(.$neutron_id), \"<\/sub><\/sup>\",                   \"<sub>\",unique(.$element_id),\"<\/sub>\",\" \",                   \"<sub>\\U03B4<\/sub>\",                   \"<sub><sup>\", unique(.$neutron_iso), \"<\/sub><\/sup>\",                   \"<sub>\",unique(.$element_iso),\"<\/sub>\", \" | X)\", sep = \"\"),       )   )  sigma_plots[[1]] +    theme(legend.position = c(0.1, 0.82))"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"estimate-niche-ellipse","dir":"Articles","previous_headings":"","what":"Estimate niche ellipse","title":"Using {nichetools} with nicheROVER","text":"use niche_ellipse() easily extract ellipse Σ\\Sigma estimate (.e., 1000). additional isotopes metrics, need create mu sigma objects pairing, currently function handles two isotopes. future, likely ability specify number isotopes default two. reason lack functionality ellipse::ellipse() can work within two-dimensions, three, create multiple ellipse() calls combination isotopes metrics haven’t time implement . function also tell long took process large sets isotope data nice know time takes function work. function also argument random default set TRUE. argument randomly subsamples returns 10 ellipse estimates total number samples taken case 1,000. set_seed argument allows change set.seed value giving numerical value make results function reproducable, default random value. highly suggest using set_seed otherwise subsample different values, default value CRAN allow default value. can change number subsamples 10 seems pretty standard. ’d like 1,000 ellipses can set random FALSE.","code":"ellipse_df <- niche_ellipse(dat_mu = df_mu, dat_sigma = df_sigma,                             set_seed = 4) #> → Total time processing was 0.06 secs"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"plot-ellipses-densities-of-each-istope-and-isotope-biplot","dir":"Articles","previous_headings":"","what":"Plot ellipses, densities of each istope, and isotope biplot","title":"Using {nichetools} with nicheROVER","text":"first plot ellipse sample_name need turn df long format iterate using imap() easily create density plots. notice use case_when() make columns element abbreviations neutron numbers used plot labeling. make density plots isotope using geom_density() Lastly use geom_point() make isotopic biplot.","code":"ellipse_plots <- ggplot() +    geom_polygon(data = ellipse_df,                mapping = aes(x = d13c, y = d15n,                              group = interaction(sample_number, sample_name),                              color = sample_name),                fill = NA,                linewidth = 0.5) +       scale_colour_viridis_d(begin = 0.25, end = 0.75,                           option = \"D\", name = \"species\",   ) +    scale_x_continuous(breaks = rev(seq(-20, -40, -2))) +   scale_y_continuous(breaks = seq(6, 16, 2)) +   theme_bw(base_size = 10) +   theme(axis.text = element_text(colour = \"black\"),         panel.grid = element_blank(),          legend.position = \"none\",          legend.title = element_text(hjust = 0.5),         legend.background = element_blank()) +    labs(x = expression(paste(delta ^ 13, \"C\")),         y = expression(paste(delta ^ 15, \"N\"))) iso_long <- df %>%   pivot_longer(cols = -species,                names_to = \"isotope\",                 values_to = \"value\") %>%    mutate(     element = case_when(       isotope == \"d15n\" ~ \"N\",       isotope == \"d13c\" ~ \"C\",     ),      neutron = case_when(       isotope == \"d15n\" ~ 15,       isotope == \"d13c\" ~ 13,     )   ) iso_density <- iso_long %>%    group_split(isotope) %>%    imap(     ~ ggplot(data = .) +        geom_density(aes(x = value,                         fill = species),                     alpha = 0.35,                     linewidth = 0.8) +       scale_fill_viridis_d(begin = 0.25, end = 0.75,                            option = \"D\", name = \"Species\") +       theme_bw(base_size = 10) +       theme(axis.text = element_text(colour = \"black\"),             panel.grid = element_blank(),              legend.position = c(0.15, 0.55),              legend.background = element_blank(),              axis.title.x = element_markdown(family = \"sans\")) +        labs(x =  paste(\"\\U03B4\",                       \"<sup>\", unique(.$neutron), \"<\/sup>\",unique(.$element),                        sep = \"\"),             y = \"Density\")   )  d13c_density <- iso_density[[1]] +    scale_x_continuous(breaks = rev(seq(-20, -34, -2)),                      limits = rev(c(-20, -34)))  d15n_density <- iso_density[[2]] +   scale_x_continuous(breaks = seq(5, 15, 2.5),                       limits = c(5, 15)) +    theme(     legend.position = \"none\"   ) iso_biplot <- ggplot() +    geom_point(data = df, aes(x = d13c, y = d15n,                             fill = species),              shape = 21, colour = \"black\",               stroke = 0.8,              size = 3, alpha = 0.70) +   scale_fill_viridis_d(begin = 0.25, end = 0.75,                        option = \"D\", name = \"species\") +   scale_x_continuous(breaks = rev(seq(-20, -39, -1))) +   scale_y_continuous(breaks = seq(5, 17, 1)) +   theme_bw(base_size = 10) +   theme(axis.text = element_text(colour = \"black\"),         panel.grid = element_blank(),          legend.position = \"none\",          legend.background = element_blank()) +    labs(x = expression(paste(delta ^ 13, \"C\")),         y = expression(paste(delta ^ 15, \"N\")))"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"use-patchwork-to-make-ellipse-density-and-biplots-into-a-paneled-figure-","dir":"Articles","previous_headings":"","what":"Use {patchwork} to make ellipse, density, and biplots into a paneled figure.","title":"Using {nichetools} with nicheROVER","text":"can also use function plot_annotation() add lettering figure can used figure description. maneuver plot_annotation() places lettering, need add plot.tag.position = c(x, y) theme() call every plot.","code":"d13c_density + ellipse_plots + iso_biplot + d15n_density +   plot_annotation(tag_levels = \"a\",                    tag_suffix = \")\")"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"determine-the-95-niche-similarties-for-each-species","dir":"Articles","previous_headings":"","what":"Determine the 95% niche similarties for each species","title":"Using {nichetools} with nicheROVER","text":"use overlap() function {nicheROVER}) estimate percentage similarity among species. set overlap assess based 95% similarities. going transform output data frame using extract_overlap() plotting can assess overall similarities among species. going take newly made data frame extract median percentage similarities 2.5% 97.5% quantiles. now going use ggplot(), geom_violin(), stat_summary() represent posterior distributions median posterior distributions. Representations posterior distributions either use mode median, mean. See following publication guide representation posterior distributions vizialations text. can extract credible intervals equal-tailed intervals using {bayestestR}.","code":"over_stat <- overlap(fish_par, nreps = nsample, nprob = 1000,                       alpha = 0.95) over_stat_df <- extract_overlap(data = over_stat) over_sum <- over_stat_df %>%    group_by(sample_name_a, sample_name_b) %>%    summarise(     median_niche_overlap = round(median(niche_overlap_perc), digits = 2),     qual_2.5 = round(quantile(niche_overlap_perc,                                probs = 0.025, na.rm = TRUE), digits = 2),      qual_97.5 = round(quantile(niche_overlap_perc,                                 probs = 0.975, na.rm = TRUE), digits = 2)   ) %>%    ungroup() %>%    pivot_longer(cols = -c(sample_name_a, sample_name_b, median_niche_overlap),                 names_to = \"percentage\",                 values_to = \"niche_overlap_qual\") %>%    mutate(     percentage = as.numeric(str_remove(percentage, \"qual_\"))   ) ggplot(data = over_stat_df, aes(x = sample_name_a,                                  y = niche_overlap_perc,                                  fill = sample_name_b)) +    geom_violin() +    stat_summary(fun.y = median, geom = \"point\",                 size = 3,                 position = position_dodge(width = 0.9)) +    geom_vline(xintercept = seq(1.5, 3.5, 1),               linetype = 2) +    scale_fill_viridis_d(begin = 0.25, end = 0.75,                        option = \"D\", name = \"Species\",                         alpha = 0.35) +    theme_bw() +    theme(     panel.grid = element_blank(),      axis.text = element_text(colour = \"black\"),      legend.background = element_blank(),     strip.background = element_blank()   ) +   labs(x = paste(\"Overlap Probability (%)\", \"\\u2013\",                   \"Niche Region Size: 95%\"),         y = \"p(Percent Overlap | X)\")"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"estimate-overall-niche-size","dir":"Articles","previous_headings":"","what":"Estimate overall niche size","title":"Using {nichetools} with nicheROVER","text":"now going estimate overall size niche posterior sample using function extract_niche_size() wrapper around niche.size() data manipulation functions.","code":"niche_size <- extract_niche_size(fish_par)"},{"path":"https://benjaminhlina.github.io/nichetools/articles/using-nichetools-with-the-package-nicheROVER.html","id":"plot-niche-size","dir":"Articles","previous_headings":"","what":"Plot niche size","title":"Using {nichetools} with nicheROVER","text":"now use geom_violin(), geom_point(), geom_errorbar() plot distribution niche size species.  Now niche sizes similarities determined can make inferences species, trophic similarities, ecosystem.","code":"ggplot(data = niche_size,         aes(x = sample_name, y = niche_size)) +    geom_violin(          width = 0.2) +    stat_summary(fun.y = median, geom = \"point\",                 size = 3,                 position = position_dodge(width = 0.9)) +    theme_bw(base_size = 15) +    theme(panel.grid = element_blank(),          axis.text = element_text(colour = \"black\")) +    labs(x = \"Species\",         y = \"Niche Size\")"},{"path":"https://benjaminhlina.github.io/nichetools/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Benjamin L. Hlina. Author, maintainer.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Swanson HK, Lysy M, Power M, Stasko AD, Johnson JD, Reist JD (2015). “new probabilistic method quantifying n-dimensional ecological niches niche overlap.” Ecology, 96(2), 318-324. doi:10.1890/14-0235.1, https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/14-0235.1. Jackson AL, Inger R, Parnell AC, Bearhop S (2011). “Comparing isotopic niche widths among within communities: SIBER – Stable Isotope Bayesian Ellipses R.” Journal Animal Ecology, 80(3), 595-602. doi:10.1111/j.1365-2656.2011.01806.x, https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.1365-2656.2011.01806.x. Layman CA, Arrington DA, Montaña CG, Post DM (2007). “Can stable isotope ratios provide community-wide measures trophic structure?” Ecology, 88(1), 42-48. doi:10.1890/0012-9658(2007)88[42:CSIRPF]2.0.CO;2. Hlina BL (2024). nichetools: Complementary Package 'nicheROVER' 'SIBER'. R package version 0.3.1, https://benjaminhlina.github.io/nichetools/.","code":"@Article{,   title = {A new probabilistic method for quantifying n-dimensional ecological niches and niche overlap.},   author = {Heidi K. Swanson and Martin Lysy and Michael Power and Ashley D. Stasko and Jim D. Johnson and James D. Reist},   journal = {Ecology},   year = {2015},   volume = {96},   number = {2},   pages = {318-324},   doi = {10.1890/14-0235.1},   url = {https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/14-0235.1}, } @Article{,   title = {Comparing isotopic niche widths among and within communities: SIBER – Stable Isotope Bayesian Ellipses in R},   author = {Andrew L. Jackson and Richard Inger and Andrew C. Parnell and Stuart Bearhop},   journal = {Journal of Animal Ecology},   year = {2011},   volume = {80},   number = {3},   pages = {595-602},   doi = {10.1111/j.1365-2656.2011.01806.x},   url = {https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.1365-2656.2011.01806.x}, } @Article{,   title = {Can stable isotope ratios provide for community-wide measures of trophic structure?},   author = {Craig A. Layman and D. Albrey Arrington and Carman G. Montaña and David M. Post},   journal = {Ecology},   year = {2007},   volume = {88},   number = {1},   pages = {42-48},   doi = {10.1890/0012-9658(2007)88[42:CSIRPF]2.0.CO;2}, } @Manual{,   title = {nichetools: Complementary Package to 'nicheROVER' and 'SIBER'},   author = {Benjamin L. Hlina},   year = {2024},   note = {R package version 0.3.1},   url = {https://benjaminhlina.github.io/nichetools/}, }"},{"path":"https://benjaminhlina.github.io/nichetools/index.html","id":"nichetools-","dir":"","previous_headings":"","what":"Complementary Package to nicheROVER and SIBER","title":"Complementary Package to nicheROVER and SIBER","text":"{nichetools} complementary package {nicheROVER} {SIBER} allows user extract Bayesian estimates data objects created {nicheROVER} {SIBER}(e.g., niche size similarities).","code":""},{"path":"https://benjaminhlina.github.io/nichetools/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Complementary Package to nicheROVER and SIBER","text":"can install development version {nichetools} using following: can install r-universe version {nichetools} using following: can install CRAN version {nichetools} using following:","code":"install.packages(\"devtools\") devtools::install_github(\"benjaminhlina/nichetools\") install.packages(\"nichetools\",                   repos = c(\"https://benjaminhlina.r-universe.dev\",                             \"https://cran.r-project.org\")) install.packages(\"nichetools\")"},{"path":"https://benjaminhlina.github.io/nichetools/index.html","id":"vignette","dir":"","previous_headings":"","what":"Vignette","title":"Complementary Package to nicheROVER and SIBER","text":"loaded {nichetools} {nicheROVER} {SIBER} can access vignettes using following code: can also use following see vignettes: vignettes also available online articles section website. See following links, use {nichetools} nicheROVER use {nichetools} SIBER blog. highly suggest going vignettes walk use {nichetools} tandem {nicheROVER} {SIBER}.","code":"vignette(\"using-nichetools-with-the-package-nicheROVER\") vignette(\"using-nichetools-with-the-package-SIBER\") browseVignettes(\"nichetools\")"},{"path":"https://benjaminhlina.github.io/nichetools/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Complementary Package to nicheROVER and SIBER","text":"cite package please cite following publications Swanson, H.K., Lysy, M., Power, M., Stasko, .D., Johnson, J.D., Reist, J.D. 2015. new probabilistic method quantifying n-dimensional ecological niches niche overlap. Ecology 96(2): 318–324. doi:10.1890/14-0235.1 Jackson, .L., Inger, R., Parnell, .C., Bearhop, S. 2011. Comparing isotopic niche widths among within communities: SIBER – Stable Isotope Bayesian Ellipses R. Journal Animal Ecology 80(3): 595–602. doi:10.1111/j.1365-2656.2011.01806.x. Layman, C.., Arrington, D.., Montaña, C.G., Post, D.M. 2007. Can stable isotope ratios provide community-wide measures trophic structure? Ecology 88(1): 42–48. link Hlina B.L. 2024. nichetools: Complementary package nicheROVER SIBER. R package version 0.3.1. https://benjaminhlina.github.io/nichetools/","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/create_comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"create comparisons — create_comparisons","title":"create comparisons — create_comparisons","text":"Creates list comparisons needed create  Bayesian maximum-likelihood estimates proportion niche similarities.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/create_comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create comparisons — create_comparisons","text":"","code":"create_comparisons(data, comparison = c(\"within\", \"among\"))"},{"path":"https://benjaminhlina.github.io/nichetools/reference/create_comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create comparisons — create_comparisons","text":"data data.frame names community group names comparison characterthat either \"within\" \"among\" indicating whether comparisons within community groups among communities groups.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/create_comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"create comparisons — create_comparisons","text":"","code":"# ---- load siber ---- library(SIBER)  # ---- create community names data frame ---- # uncomment to use # str(demo.siber.data.2)  demo.siber.data.2$group_name <- as.factor(demo.siber.data.2$group)  demo.siber.data.2$group <- as.numeric(demo.siber.data.2$group_name) |> as.character()  demo.siber.data.2$community_names <- as.factor(demo.siber.data.2$community)  demo.siber.data.2$community <- as.numeric(demo.siber.data.2$community_names) |> as.character()  cg_names <- demo.siber.data.2 |> dplyr::distinct(community, group, community_names, group_name)  # ---- create comparsions ---- create_comparisons(cg_names,                   comparison = \"within\") #> $`1.1_1.2` #> # A tibble: 1 × 2 #>   cg_1  cg_2  #>   <chr> <chr> #> 1 1.1   1.2   #>  #> $`1.1_1.3` #> # A tibble: 1 × 2 #>   cg_1  cg_2  #>   <chr> <chr> #> 1 1.1   1.3   #>  #> $`1.2_1.3` #> # A tibble: 1 × 2 #>   cg_1  cg_2  #>   <chr> <chr> #> 1 1.2   1.3   #>  #> $`2.1_2.4` #> # A tibble: 1 × 2 #>   cg_1  cg_2  #>   <chr> <chr> #> 1 2.1   2.4   #>"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_group_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"extract maximum-likelihood estimates for group metrics — extract_group_metrics","title":"extract maximum-likelihood estimates for group metrics — extract_group_metrics","text":"Extract group metrics within community matrix object produced groupMetricsML() function SIBER. metrics following   convex hull total area (TA), Standard Ellipse Area (SEA), corresponding small sample size corrected version SEAc based maximum likelihood estimates means covariance matrices group.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_group_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract maximum-likelihood estimates for group metrics — extract_group_metrics","text":"","code":"extract_group_metrics(data = NULL, community_df = NULL, data_format = NULL)"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_group_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract maximum-likelihood estimates for group metrics — extract_group_metrics","text":"data matrix produced function groupMetricsML() package SIBER. community_df four column data frame. One columns named community data column numeric character string(e.g., \"1\", \"2\", \"3\"). order community names used join actual community names correct data. class values required function, createSiberObject() SIBER. second column names groups needed supply required function, createSiberObject() SIBER. third fourth columns contains actual names communities groups user working (e.g., \"region\", \"common_name\"). data_format character string decides whether returned object long wide format. Default \"long\", alternative supplied \"wide\".","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_group_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract maximum-likelihood estimates for group metrics — extract_group_metrics","text":"tibble containing four rows data_format set default long. four rows following, community, the_name_of_the_communities, metric post_est.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_group_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract maximum-likelihood estimates for group metrics — extract_group_metrics","text":"","code":"library(SIBER)  # ---- create community names data frame ---- # uncomment to use # str(demo.siber.data.2)  demo.siber.data.2$group_name <- as.factor(demo.siber.data.2$group)  demo.siber.data.2$group <- as.numeric(demo.siber.data.2$group_name) |> as.character()  demo.siber.data.2$community_name <- as.factor(demo.siber.data.2$community)  demo.siber.data.2$community <- as.numeric(demo.siber.data.2$community_name) |> as.character()  cg_name <- demo.siber.data.2 |> dplyr::distinct(community, group, community_name, group_name)  # ---- create comparsions ----  demo.siber.data.2 <- demo.siber.data.2[,1:4]  siber_example <- createSiberObject(demo.siber.data.2)  # extract group metrics group_ml <- groupMetricsML(siber_example)  group_convert <- extract_group_metrics(data = group_ml,                                 community_df = cg_name)"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_layman.html","id":null,"dir":"Reference","previous_headings":"","what":"extract Layman metrics — extract_layman","title":"extract Layman metrics — extract_layman","text":"Extract Bayesian estimates following six layman metrics, \\(\\delta^{13}\\)C range,  \\(\\delta^{15}\\)N range, total area (TA), distance centroid (CD), distance nearest neighbour (NND), standard deviation distance nearest neighbour (SDNND) data objects created SIBER. learn following metrics please review Layman et al. (2008).","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_layman.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract Layman metrics — extract_layman","text":"","code":"extract_layman(   data,   type = NULL,   community_df = NULL,   data_format = NULL,   isotope_x = NULL,   isotope_y = NULL,   element_x = NULL,   element_y = NULL )"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_layman.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract Layman metrics — extract_layman","text":"data list created function bayesianLayman() package SIBER. type character either \"bay\" \"ml\" indicates whether community metrics extracted Bayesian analysis maximum-likelihood. community_df two column data frame. One columns named community data column numerics character string(e.g., \"1\", \"2\", \"3\"). order community names used join actual community names correct data. class values required function, createSiberObject() SIBER. second column contains actual names communities user working (e.g., \"region\"). data_format character string decides whether returned object long wide format. Default \"long\", alternative supplied \"wide\". isotope_x numeric used labeling processes range x. Default 13 (e.g., \\(\\delta\\)^13 C). create column called labels, created data_format set long. isotope_y numeric used labeling processes range y isotope. Default 15 (e.g., \\(\\delta\\)^15 N). #' create column called labels, created data_format set long. element_x character used labeling process range x isotope. Default C (e.g., \\(\\delta\\)^13 C). create column called labels, created data_format set long. element_y character used labeling process range y isotope. Default N (e.g., \\(\\delta\\)^13 N). #' create column called labels, created data_format set long.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_layman.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract Layman metrics — extract_layman","text":"tibble containing four rows data_format set default long. four rows following, community, the_name_of_the_communities, metric post_est.","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_layman.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract Layman metrics — extract_layman","text":"","code":"library(SIBER)  # ---- bring in SIBER demo data ---- # uncomenet to use # str(demo.siber.data)  # ---- create community names data frame ---- # uncomment to use # str(demo.siber.data.2)  demo.siber.data.2$group_name <- as.factor(demo.siber.data.2$group)  demo.siber.data.2$group <- as.numeric(demo.siber.data.2$group_name) |> as.character()  demo.siber.data.2$community_names <- as.factor(demo.siber.data.2$community)  demo.siber.data.2$community <- as.numeric(demo.siber.data.2$community_names) |> as.character() c_names <- demo.siber.data.2 |> dplyr::distinct(community, community_names)   demo.siber.data_2 <- demo.siber.data.2[,1:4] # ---- create the siber object ---- siber.example <- createSiberObject(demo.siber.data_2)  # ---- view Bayesian estimates of mu and sigma produced by SIBER --- # uncomment to use # str(post_sam_siber)  # ---- extract posterior estimates of mu -----  mu_post <- extractPosteriorMeans(siber.example, post_sam_siber)  # ---- Bayesian estimates of layman metrics using SIBER ----  layman_b <- bayesianLayman(mu.post = mu_post)  # ---- use nichetools to extract Bayesian estimates of Layman metrics ----  layman_be <- extract_layman(layman_b, community_df = c_names)  layman_be #> # A tibble: 48,000 × 5 #>    community community_names metric   post_est labels                            #>    <chr>     <fct>           <chr>       <dbl> <fct>                             #>  1 1         dublin          dY_range     6.71 δ<sup>15<\/sup>N<br>Range          #>  2 1         dublin          dX_range     8.14 δ<sup>13<\/sup>C<br>Range          #>  3 1         dublin          TA          13.7  Total Area                        #>  4 1         dublin          CD           4.27 Distance to<br>Centroid           #>  5 1         dublin          NND          5.08 Nearest<br>Neighbor<br>Distance   #>  6 1         dublin          SDNND        3.57 SD Nearest<br>Neighbor<br>Distan… #>  7 1         dublin          dY_range     6.20 δ<sup>15<\/sup>N<br>Range          #>  8 1         dublin          dX_range     8.19 δ<sup>13<\/sup>C<br>Range          #>  9 1         dublin          TA          10.6  Total Area                        #> 10 1         dublin          CD           4.19 Distance to<br>Centroid           #> # ℹ 47,990 more rows"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_mu.html","id":null,"dir":"Reference","previous_headings":"","what":"extract \\(\\mu\\) — extract_mu","title":"extract \\(\\mu\\) — extract_mu","text":"Extract Bayesian estimates \\(\\mu\\) data objects created nicheROVER SIBER.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_mu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract \\(\\mu\\) — extract_mu","text":"","code":"extract_mu(   data,   pkg = NULL,   isotope_names = NULL,   data_format = NULL,   community_df = NULL )"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_mu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract \\(\\mu\\) — extract_mu","text":"data list created function niw.post() siberMVN() package nicheROVER SIBER, respectfully. pkg character string name package using. Defaults \"nicheROVER\". Alternatively user can supply argument \"SIBER\". isotope_names vector character string used change column name isotopes used analysis. Defaults c(\"d13c\", \"d15n\"). data_format character string decides whether returned object long wide format. Default \"long\", alternative supplied \"wide\". community_df four column data frame. One columns named community data column numeric character string(e.g., \"1\", \"2\", \"3\"). order community names used join actual community names correct data. class values required function, createSiberObject() SIBER. second column names groups needed supply required function, createSiberObject() SIBER. third fourth columns contains actual names communities groups user working (e.g., \"region\", \"common_name\").","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_mu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract \\(\\mu\\) — extract_mu","text":"Returns tibble extracted estimates \\(\\mu\\) created function niw.post() siberMVN() packages nicheROVER. SIBER. tibble contain five columns following order, metric, sample_name, sample_number, names isotope columns supplied niw.post()  siberMVN() (e.g., d13c  d15n ).","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_mu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract \\(\\mu\\) — extract_mu","text":"","code":"extract_mu( data = niw_fish_post ) #> # A tibble: 8,000 × 5 #>    metric sample_name sample_number isotope mu_est #>    <chr>  <chr>               <int> <chr>    <dbl> #>  1 mu     ARCS                    1 d13c     -23.8 #>  2 mu     ARCS                    1 d15n      12.6 #>  3 mu     ARCS                    2 d13c     -23.7 #>  4 mu     ARCS                    2 d15n      12.6 #>  5 mu     ARCS                    3 d13c     -24.2 #>  6 mu     ARCS                    3 d15n      12.4 #>  7 mu     ARCS                    4 d13c     -24.1 #>  8 mu     ARCS                    4 d15n      12.7 #>  9 mu     ARCS                    5 d13c     -23.9 #> 10 mu     ARCS                    5 d15n      12.6 #> # ℹ 7,990 more rows  library(SIBER)  # ---- create community names data frame ---- # uncomment to use # str(demo.siber.data.2)  demo.siber.data.2$group_name <- as.factor(demo.siber.data.2$group)  demo.siber.data.2$group <- as.numeric(demo.siber.data.2$group_name) |> as.character()  demo.siber.data.2$community_name <- as.factor(demo.siber.data.2$community)  demo.siber.data.2$community <- as.numeric(demo.siber.data.2$community_name) |> as.character()  cg_name <- demo.siber.data.2 |> dplyr::distinct(community, group, community_name, group_name)   extract_mu( data = post_sam_siber, pkg = \"SIBER\", community_df = cg_name ) #> # A tibble: 40,000 × 9 #>    metric community group sample_name sample_number community_name group_name #>    <chr>  <chr>     <chr> <chr>               <int> <fct>          <fct>      #>  1 mu     1         1     1.1                     1 dublin         city       #>  2 mu     1         1     1.1                     1 dublin         city       #>  3 mu     1         1     1.1                     2 dublin         city       #>  4 mu     1         1     1.1                     2 dublin         city       #>  5 mu     1         1     1.1                     3 dublin         city       #>  6 mu     1         1     1.1                     3 dublin         city       #>  7 mu     1         1     1.1                     4 dublin         city       #>  8 mu     1         1     1.1                     4 dublin         city       #>  9 mu     1         1     1.1                     5 dublin         city       #> 10 mu     1         1     1.1                     5 dublin         city       #> # ℹ 39,990 more rows #> # ℹ 2 more variables: isotope <chr>, mu_est <dbl>"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_niche_size.html","id":null,"dir":"Reference","previous_headings":"","what":"extract niche size — extract_niche_size","title":"extract niche size — extract_niche_size","text":"Extract niche size based elliptical niche region Bayesian estimates sigma created function niw.post() siberEllipses() package nicheROVER SIBER, respectfully. nicheROVER function wrapper around nicheROVER::niche.size.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_niche_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract niche size — extract_niche_size","text":"","code":"extract_niche_size(   data,   pkg = NULL,   name = NULL,   prob = NULL,   community_df = NULL )"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_niche_size.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract niche size — extract_niche_size","text":"data list matrix created function niw.post() siberEllipses() package nicheROVER SIBER, respectfully. pkg character string name package using. Defaults \"nicheROVER\". Alternatively user can supply argument \"SIBER\". name character string assigned column name groups. Default sample_name. used pkg set \"nicheROVER\". prob numeric bound 0 1 indicating probabilistic niche size. Default 0.95. used pkg set \"nicheROVER\". community_df four column data frame. One columns named community data column numeric character string(e.g., \"1\", \"2\", \"3\"). order community names used join actual community names correct data. class values required function, createSiberObject() SIBER. second column names groups needed supply required function, createSiberObject() SIBER. third fourth columns contains actual names communities groups user working (e.g., \"region\", \"common_name\").","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_niche_size.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract niche size — extract_niche_size","text":"pkg set \"nicheROVER\" tibble containing three rows, sample_name, id, niche_size returned.","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_niche_size.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract niche size — extract_niche_size","text":"","code":"extract_niche_size(data = niw_fish_post) #> # A tibble: 4,000 × 3 #>    sample_name id    niche_size #>    <chr>       <chr>      <dbl> #>  1 ARCS        1           13.6 #>  2 ARCS        2           14.8 #>  3 ARCS        3           13.4 #>  4 ARCS        4           13.6 #>  5 ARCS        5           13.7 #>  6 ARCS        6           13.2 #>  7 ARCS        7           18.3 #>  8 ARCS        8           13.9 #>  9 ARCS        9           14.3 #> 10 ARCS        10          14.3 #> # ℹ 3,990 more rows"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_overlap.html","id":null,"dir":"Reference","previous_headings":"","what":"extract overlap — extract_overlap","title":"extract overlap — extract_overlap","text":"Extract Bayesian estimates similarities among groups produced following function overlap() package nicheROVER.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_overlap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract overlap — extract_overlap","text":"","code":"extract_overlap(data, name_a = NULL, name_b = NULL)"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_overlap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract overlap — extract_overlap","text":"data array object containing matrices created function overlap() package nicheROVER. name_a character string supply first sample_name used overlap(). Defaults \"sample_name_a\". name_b character string supply second sample_name used overlap(). Defaults \"sample_name_b\".","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_overlap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract overlap — extract_overlap","text":"tibble containing five rows, sample_name_a, id, sample_name_b, sample_number, niche_overlap.","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_overlap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract overlap — extract_overlap","text":"","code":"extract_overlap(data = over_stat) #> # A tibble: 16,000 × 6 #>    sample_name_a    id sample_name_b sample_number niche_overlap #>    <chr>         <int> <chr>         <chr>                 <dbl> #>  1 ARCS              1 ARCS          1                    NA     #>  2 ARCS              1 BDWF          1                     0.073 #>  3 ARCS              1 LKWF          1                     0.787 #>  4 ARCS              1 LSCS          1                     0.737 #>  5 ARCS              1 ARCS          2                    NA     #>  6 ARCS              1 BDWF          2                     0.049 #>  7 ARCS              1 LKWF          2                     0.484 #>  8 ARCS              1 LSCS          2                     0.671 #>  9 ARCS              1 ARCS          3                    NA     #> 10 ARCS              1 BDWF          3                     0.095 #> # ℹ 15,990 more rows #> # ℹ 1 more variable: niche_overlap_perc <dbl>"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_sigma.html","id":null,"dir":"Reference","previous_headings":"","what":"extract \\(\\Sigma\\) — extract_sigma","title":"extract \\(\\Sigma\\) — extract_sigma","text":"Extract Bayesian estimates \\(\\Sigma\\) data objects created nicheROVER SIBER.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_sigma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract \\(\\Sigma\\) — extract_sigma","text":"","code":"extract_sigma(   data,   pkg = NULL,   isotope_n = NULL,   isotope_names = NULL,   data_format = NULL )"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_sigma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract \\(\\Sigma\\) — extract_sigma","text":"data list created function niw.post() siberMVN() package nicheROVER SIBER, respectfully. pkg character string name package using. Defaults \"nicheROVER\". Alternatively user can supply argument \"SIBER\". isotope_n numeric either 2 3 number isotopes used anlsysis. default 2. isotope_names vector character string used change column name isotopes used analysis. Defaults c(\"d13c\", \"d15n\"). data_format character string decides whether returned object long wide format. Default \"wide\", alternative supplied \"long\".","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_sigma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract \\(\\Sigma\\) — extract_sigma","text":"Returns tibble extracted estimates \\(\\Sigma\\) created function niw.post() siberMVN() packages nicheROVER. SIBER. returned object contain five columns following order data_format set \"wide\", metric, id, sample_name, isotope, sample_number, posterior sample \\(\\Sigma\\) (e.g., d13c d15n).","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_sigma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract \\(\\Sigma\\) — extract_sigma","text":"","code":"extract_sigma( data = niw_fish_post ) #> # A tibble: 8,000 × 6 #>    metric sample_name isotope sample_number  d13c  d15n #>    <chr>  <chr>       <chr>   <chr>         <dbl> <dbl> #>  1 sigma  ARCS        d13c    1             1.07  0.305 #>  2 sigma  ARCS        d15n    1             0.305 0.571 #>  3 sigma  ARCS        d13c    2             1.01  0.221 #>  4 sigma  ARCS        d15n    2             0.221 0.657 #>  5 sigma  ARCS        d13c    3             1.21  0.486 #>  6 sigma  ARCS        d15n    3             0.486 0.616 #>  7 sigma  ARCS        d13c    4             1.14  0.352 #>  8 sigma  ARCS        d15n    4             0.352 0.570 #>  9 sigma  ARCS        d13c    5             0.788 0.376 #> 10 sigma  ARCS        d15n    5             0.376 0.849 #> # ℹ 7,990 more rows  extract_sigma( data = post_sam_siber, pkg = \"SIBER\" ) #> # A tibble: 40,000 × 6 #>    metric sample_name isotope sample_number   d13c   d15n #>    <chr>  <chr>       <chr>           <int>  <dbl>  <dbl> #>  1 sigma  1.1         d13c                1  1.58  -0.808 #>  2 sigma  1.1         d15n                1 -0.808  2.22  #>  3 sigma  1.1         d13c                2  1.49  -0.990 #>  4 sigma  1.1         d15n                2 -0.990  3.64  #>  5 sigma  1.1         d13c                3  1.60  -1.30  #>  6 sigma  1.1         d15n                3 -1.30   3.78  #>  7 sigma  1.1         d13c                4  1.61  -1.48  #>  8 sigma  1.1         d15n                4 -1.48   3.69  #>  9 sigma  1.1         d13c                5  1.54  -0.892 #> 10 sigma  1.1         d15n                5 -0.892  2.58  #> # ℹ 39,990 more rows"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_similarities.html","id":null,"dir":"Reference","previous_headings":"","what":"extract similarities — extract_similarities","title":"extract similarities — extract_similarities","text":"Extract niche similarities objects created {SIBER}.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_similarities.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract similarities — extract_similarities","text":"","code":"extract_similarities(data, type = c(\"bay\", \"ml\"), community_df = NULL)"},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_similarities.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract similarities — extract_similarities","text":"data list results either maxLikOverlap() bayesianOverlap(). type character either \"bay\" \"ml\" indicates whether community metrics extracted Bayesian analysis maximum-likelihood. community_df four column data frame. One columns named community data column numeric character string(e.g., \"1\", \"2\", \"3\"). order community names used join actual community names correct data. class values required function, createSiberObject() SIBER. second column names groups needed supply required function, createSiberObject() SIBER. third fourth columns contains actual names communities groups user working (e.g., \"region\", \"common_name\").","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/extract_similarities.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"extract similarities — extract_similarities","text":"","code":"library(purrr) library(SIBER)  # ---- create community names data frame ---- # uncomment to use # str(demo.siber.data.2)  demo.siber.data.2$group_name <- as.factor(demo.siber.data.2$group)  demo.siber.data.2$group <- as.numeric(demo.siber.data.2$group_name) |> as.character()  demo.siber.data.2$community_name <- as.factor(demo.siber.data.2$community)  demo.siber.data.2$community <- as.numeric(demo.siber.data.2$community_name) |> as.character()  cg_name <- demo.siber.data.2 |> dplyr::distinct(community, group, community_name, group_name)  # ---- create comparsions ---- cg_names_within_c <- create_comparisons(cg_name,                                         comparison = \"within\")  demo.siber.data.2 <- demo.siber.data.2[,1:4]  siber_example <- createSiberObject(demo.siber.data.2)  ml_within_overlap <- cg_names_within_c |> map(~ maxLikOverlap(.x$cg_1, .x$cg_2, siber_example, p.interval = NULL, n = 100), .progress = TRUE)  ml_95_within_com <- extract_similarities(ml_within_overlap, type = \"ml\", community_df = cg_name)"},{"path":"https://benjaminhlina.github.io/nichetools/reference/mu_est_long.html","id":null,"dir":"Reference","previous_headings":"","what":"A data.frame containing posterior estimates of \\(\\mu\\) — mu_est_long","title":"A data.frame containing posterior estimates of \\(\\mu\\) — mu_est_long","text":"Posterior estimates \\(\\mu\\) using fish data set nicheROVER, using  Normal-Inverse-Wishart (NIW) priors.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/mu_est_long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data.frame containing posterior estimates of \\(\\mu\\) — mu_est_long","text":"","code":"mu_est_long"},{"path":"https://benjaminhlina.github.io/nichetools/reference/mu_est_long.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data.frame containing posterior estimates of \\(\\mu\\) — mu_est_long","text":"data.frame containing 8,000 rows 7 variables metric name metric extracted niw.post() species species abbreviation sample_number sample number 1-1000 isotope column isotope name mu_est estimate mu produced niw.post() element isotopic element used labelling neutron neutron number used labelling","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/niche_ellipse.html","id":null,"dir":"Reference","previous_headings":"","what":"Create ellipses based on Bayesian estimates of \\(\\mu\\) and \\(\\Sigma\\) — niche_ellipse","title":"Create ellipses based on Bayesian estimates of \\(\\mu\\) and \\(\\Sigma\\) — niche_ellipse","text":"function allows user supply Bayesian estimates \\(\\mu\\) \\(\\Sigma\\) create estimated Bayesian ellipse niche region.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/niche_ellipse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create ellipses based on Bayesian estimates of \\(\\mu\\) and \\(\\Sigma\\) — niche_ellipse","text":"","code":"niche_ellipse(   dat_mu,   dat_sigma,   isotope_a = NULL,   isotope_b = NULL,   p_ell = NULL,   random = NULL,   set_seed = NULL,   n = NULL,   message = TRUE )"},{"path":"https://benjaminhlina.github.io/nichetools/reference/niche_ellipse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create ellipses based on Bayesian estimates of \\(\\mu\\) and \\(\\Sigma\\) — niche_ellipse","text":"dat_mu data.frame containing \\(\\mu\\) Bayesian estimates. data.frame needs long format \\(\\mu\\) estimate isotope stacked top . can produced using extract_mu(). dat_sigma data.frame containing \\(\\Sigma\\) Bayesian estimates. data.frame needs wide format, \\(\\Sigma\\) (covariance) matrices stacked top . See example convert wide format. can produced using extract_sigma(). isotope_a character string column name first isotope used dat_sigma. Defaults \"d13c\". isotope_b character string column name second isotope used dat_sigma. Defaults \"d15n\". p_ell confidence interval ellipse estimate. Default 0.95 (.e., 95% confidence interval). value bound 0 1 numeric. random logical value indicating whether randomly sample posterior distributions \\(\\mu\\) \\(\\Sigma\\) create sub-sample ellipse. Default TRUE. set_seed numerical value set seed random sampling. Default random value. consistently sample subsample, please supply numerical value (e.g., 4). highly suggested use set_seed make function results randomly sampling reproducible. n numerical value controls number random samples. Default 10. message control whether time processing displayed end function. Default TRUE.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/niche_ellipse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create ellipses based on Bayesian estimates of \\(\\mu\\) and \\(\\Sigma\\) — niche_ellipse","text":"tibble containing, sample_name, sample_number, isotopes used estimation ellipse (.e.,  d13c d15n).","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/reference/niche_ellipse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create ellipses based on Bayesian estimates of \\(\\mu\\) and \\(\\Sigma\\) — niche_ellipse","text":"","code":"niche_ellipse(dat_mu = mu_est_long,               dat_sigma = sigma_est_wide) #> → Total time processing was 0.08 secs #> # A tibble: 4,000 × 4 #>    sample_name sample_number  d13c  d15n #>    <chr>               <dbl> <dbl> <dbl> #>  1 ARCS                  126 -21.9  14.0 #>  2 ARCS                  126 -22.0  14.0 #>  3 ARCS                  126 -22.1  14.1 #>  4 ARCS                  126 -22.2  14.1 #>  5 ARCS                  126 -22.3  14.2 #>  6 ARCS                  126 -22.5  14.2 #>  7 ARCS                  126 -22.6  14.2 #>  8 ARCS                  126 -22.7  14.2 #>  9 ARCS                  126 -22.8  14.2 #> 10 ARCS                  126 -23.0  14.2 #> # ℹ 3,990 more rows"},{"path":"https://benjaminhlina.github.io/nichetools/reference/nichetools-package.html","id":null,"dir":"Reference","previous_headings":"","what":"nichetools: Complementary Package to 'nicheROVER' and 'SIBER' — nichetools-package","title":"nichetools: Complementary Package to 'nicheROVER' and 'SIBER' — nichetools-package","text":"Provides functions complementary packages 'nicheROVER' 'SIBER' allowing user extract Bayesian estimates data objects created packages 'nicheROVER' 'SIBER'. Please see following publications detailed methods 'nicheROVER' 'SIBER' Hansen et al. (2015) doi:10.1890/14-0235.1 , Jackson et al. (2011) doi:10.1111/j.1365-2656.2011.01806.x , Layman et al. (2007) doi:10.1890/0012-9658(2007)88[42:CSIRPF]2.0.CO;2 , respectfully.","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/reference/nichetools-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nichetools: Complementary Package to 'nicheROVER' and 'SIBER' — nichetools-package","text":"Maintainer: Benjamin L. Hlina benjamin.hlina@gmail.com","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/niw_fish_post.html","id":null,"dir":"Reference","previous_headings":"","what":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {nicheROVER} — niw_fish_post","title":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {nicheROVER} — niw_fish_post","text":"Posterior estimates \\(\\mu\\) \\(\\Sigma\\) using fish data set nicheROVER, using Normal-Inverse-Wishart (NIW) priors. list produced  using function niw.post() nicheROVER.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/niw_fish_post.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {nicheROVER} — niw_fish_post","text":"","code":"niw_fish_post"},{"path":"https://benjaminhlina.github.io/nichetools/reference/niw_fish_post.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {nicheROVER} — niw_fish_post","text":"list elements \\(\\mu\\) \\(\\Sigma\\) sizes c(nsamples, length(lambda)) c(dim(Psi)).","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/over_stat.html","id":null,"dir":"Reference","previous_headings":"","what":"A data.frame containing the estimates of percentage of overlap among groups — over_stat","title":"A data.frame containing the estimates of percentage of overlap among groups — over_stat","text":"Estimates percentage overlap among example species used nicheROVER.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/over_stat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data.frame containing the estimates of percentage of overlap among groups — over_stat","text":"","code":"over_stat"},{"path":"https://benjaminhlina.github.io/nichetools/reference/over_stat.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data.frame containing the estimates of percentage of overlap among groups — over_stat","text":"arraycontaining matrices percent overlap group used Bayesian estimates \\(\\mu\\) \\(\\Sigma\\) using Normal-Inverse-Wishart (NIW) priors calculated niw.post().","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/post_sam_siber.html","id":null,"dir":"Reference","previous_headings":"","what":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {SIBER} — post_sam_siber","title":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {SIBER} — post_sam_siber","text":"Posterior estimates \\(\\mu\\) \\(\\Sigma\\) using demo.siber.data.2 data set SIBER. list produced  using function siberMVN() SIBER.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/post_sam_siber.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {SIBER} — post_sam_siber","text":"","code":"post_sam_siber"},{"path":"https://benjaminhlina.github.io/nichetools/reference/post_sam_siber.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A list of the posterior estimates of \\(\\mu\\) and \\(\\Sigma\\) from {SIBER} — post_sam_siber","text":"list estimates \\(\\mu\\) \\(\\Sigma\\) species group.","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/sigma_est_wide.html","id":null,"dir":"Reference","previous_headings":"","what":"A data.frame containing posterior estimates of \\(\\Sigma\\) — sigma_est_wide","title":"A data.frame containing posterior estimates of \\(\\Sigma\\) — sigma_est_wide","text":"Posterior estimates \\(\\Sigma\\) using fish data set nicheROVER, using Normal-Inverse-Wishart (NIW) priors","code":""},{"path":"https://benjaminhlina.github.io/nichetools/reference/sigma_est_wide.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A data.frame containing posterior estimates of \\(\\Sigma\\) — sigma_est_wide","text":"","code":"sigma_est_wide"},{"path":"https://benjaminhlina.github.io/nichetools/reference/sigma_est_wide.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A data.frame containing posterior estimates of \\(\\Sigma\\) — sigma_est_wide","text":"data.frame containing 8,000 rows 6 variables metric name metric extracted niw.post() species species abbreviation isotope column isotope name sample_number sample number 1-1000 d15n estimate \\(\\Sigma\\) d15n produced niw.post() d13c estimate \\(\\Sigma\\) d13c produced niw.post()","code":""},{"path":"https://benjaminhlina.github.io/nichetools/news/index.html","id":"nichetools-030","dir":"Changelog","previous_headings":"","what":"nichetools 0.3.0","title":"nichetools 0.3.0","text":"CRAN release: 2024-08-26","code":""},{"path":"https://benjaminhlina.github.io/nichetools/news/index.html","id":"id_22-august-0-3-0","dir":"Changelog","previous_headings":"","what":"22-August-2024","title":"nichetools 0.3.0","text":"*extract_similiarties(), create_comparisons(), extract_group_metric() well additional arguments added extract_layman() extract either maximum-likelihood Bayesian estimates. Test new functions added. {SIBER} vignette now completed","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/news/index.html","id":"id_21-june-0-2-1","dir":"Changelog","previous_headings":"","what":"21-June-2024","title":"nichetools 0.2.1","text":"extract_layman implemented Tests added function","code":""},{"path":"https://benjaminhlina.github.io/nichetools/news/index.html","id":"nichetools-020","dir":"Changelog","previous_headings":"","what":"nichetools 0.2.0","title":"nichetools 0.2.0","text":"CRAN release: 2024-06-07","code":""},{"path":"https://benjaminhlina.github.io/nichetools/news/index.html","id":"id_03-june-0-2-0","dir":"Changelog","previous_headings":"","what":"03-June-2024","title":"nichetools 0.2.0","text":"functions now fully support {SIBER} functions now extract randomly sampled ellipse","code":""},{"path":"https://benjaminhlina.github.io/nichetools/news/index.html","id":"id_16-may-0-2-0","dir":"Changelog","previous_headings":"","what":"16-May-2024","title":"nichetools 0.2.0","text":"Update documentation CRAN submission Update functions allow use {SIBER}","code":""},{"path":[]},{"path":"https://benjaminhlina.github.io/nichetools/news/index.html","id":"id_19-march-0-1-0","dir":"Changelog","previous_headings":"","what":"19-March-2024","title":"nichetools 0.1.0","text":"Initial CRAN submission. Initial release {nichetools} Current features include functions around extracting mu, sigma, niche size, similarities, niche ellipse estimates.","code":""}]
